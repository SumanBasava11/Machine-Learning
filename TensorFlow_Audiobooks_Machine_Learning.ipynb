{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idFVJGs5Tm6N"
      },
      "source": [
        "## Create the machine learning algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5JnMmO3Tm6O"
      },
      "source": [
        "### Import the relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ppiH_9WzTm6O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxjFl9s-Tm6P"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gKceGGlyTm6P"
      },
      "outputs": [],
      "source": [
        "# let's create a temporary variable npz, where we will store each of the three Audiobooks datasets\n",
        "npz = np.load('/content/Audiobooks_data_train.npz')\n",
        "\n",
        "# we extract the inputs using the keyword under which we saved them\n",
        "# to ensure that they are all floats, let's also take care of that\n",
        "train_inputs = npz['inputs'].astype(float)\n",
        "# targets must be int because of sparse_categorical_crossentropy (we want to be able to smoothly one-hot encode them)\n",
        "train_targets = npz['targets'].astype(int)\n",
        "\n",
        "# we load the validation data in the temporary variable\n",
        "npz = np.load('/content/Audiobooks_data_validation.npz')\n",
        "# we can load the inputs and the targets in the same line\n",
        "validation_inputs, validation_targets = npz['inputs'].astype(float), npz['targets'].astype(int)\n",
        "\n",
        "# we load the test data in the temporary variable\n",
        "npz = np.load('/content/Audiobooks_data_test.npz')\n",
        "# we create 2 variables that will contain the test inputs and the test targets\n",
        "test_inputs, test_targets = npz['inputs'].astype(float), npz['targets'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wu1S3ukTm6P"
      },
      "source": [
        "### Model\n",
        "Outline, optimizers, loss, early stopping and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRvytmMwTm6P",
        "outputId": "dfa663fd-f4c7-45f6-82ad-62b4c9a33028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "112/112 - 2s - 18ms/step - accuracy: 0.6868 - loss: 0.5865 - val_accuracy: 0.7450 - val_loss: 0.4544\n",
            "Epoch 2/100\n",
            "112/112 - 0s - 4ms/step - accuracy: 0.7564 - loss: 0.4378 - val_accuracy: 0.7808 - val_loss: 0.3908\n",
            "Epoch 3/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7759 - loss: 0.3972 - val_accuracy: 0.7785 - val_loss: 0.3577\n",
            "Epoch 4/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7879 - loss: 0.3803 - val_accuracy: 0.7808 - val_loss: 0.3417\n",
            "Epoch 5/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7787 - loss: 0.3719 - val_accuracy: 0.8233 - val_loss: 0.3342\n",
            "Epoch 6/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7815 - loss: 0.3610 - val_accuracy: 0.7830 - val_loss: 0.3332\n",
            "Epoch 7/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7843 - loss: 0.3598 - val_accuracy: 0.8009 - val_loss: 0.3387\n",
            "Epoch 8/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7888 - loss: 0.3612 - val_accuracy: 0.8188 - val_loss: 0.3215\n",
            "Epoch 9/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7966 - loss: 0.3527 - val_accuracy: 0.8121 - val_loss: 0.3271\n",
            "Epoch 10/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8036 - loss: 0.3461 - val_accuracy: 0.8188 - val_loss: 0.3307\n",
            "Epoch 11/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7896 - loss: 0.3480 - val_accuracy: 0.7875 - val_loss: 0.3399\n",
            "Epoch 12/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7963 - loss: 0.3434 - val_accuracy: 0.8188 - val_loss: 0.3218\n",
            "Epoch 13/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7871 - loss: 0.3448 - val_accuracy: 0.8031 - val_loss: 0.3236\n",
            "Epoch 14/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8011 - loss: 0.3403 - val_accuracy: 0.8166 - val_loss: 0.3241\n",
            "Epoch 15/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8005 - loss: 0.3417 - val_accuracy: 0.8300 - val_loss: 0.3188\n",
            "Epoch 16/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8002 - loss: 0.3402 - val_accuracy: 0.7808 - val_loss: 0.3342\n",
            "Epoch 17/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7966 - loss: 0.3388 - val_accuracy: 0.8076 - val_loss: 0.3278\n",
            "Epoch 18/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7952 - loss: 0.3455 - val_accuracy: 0.8166 - val_loss: 0.3219\n",
            "Epoch 19/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7991 - loss: 0.3397 - val_accuracy: 0.8166 - val_loss: 0.3262\n",
            "Epoch 20/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8055 - loss: 0.3381 - val_accuracy: 0.8277 - val_loss: 0.3162\n",
            "Epoch 21/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7985 - loss: 0.3412 - val_accuracy: 0.8322 - val_loss: 0.3155\n",
            "Epoch 22/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8094 - loss: 0.3341 - val_accuracy: 0.8233 - val_loss: 0.3229\n",
            "Epoch 23/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8033 - loss: 0.3370 - val_accuracy: 0.8233 - val_loss: 0.3215\n",
            "Epoch 24/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8013 - loss: 0.3387 - val_accuracy: 0.8188 - val_loss: 0.3156\n",
            "Epoch 25/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8044 - loss: 0.3326 - val_accuracy: 0.8367 - val_loss: 0.3170\n",
            "Epoch 26/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8058 - loss: 0.3329 - val_accuracy: 0.8322 - val_loss: 0.3200\n",
            "Epoch 27/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8036 - loss: 0.3386 - val_accuracy: 0.8322 - val_loss: 0.3153\n",
            "Epoch 28/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8047 - loss: 0.3356 - val_accuracy: 0.8076 - val_loss: 0.3252\n",
            "Epoch 29/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8002 - loss: 0.3381 - val_accuracy: 0.8233 - val_loss: 0.3214\n",
            "Epoch 30/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7997 - loss: 0.3411 - val_accuracy: 0.7897 - val_loss: 0.3413\n",
            "Epoch 31/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8033 - loss: 0.3359 - val_accuracy: 0.8322 - val_loss: 0.3194\n",
            "Epoch 32/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7946 - loss: 0.3364 - val_accuracy: 0.8322 - val_loss: 0.3167\n",
            "Epoch 33/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8120 - loss: 0.3314 - val_accuracy: 0.8367 - val_loss: 0.3135\n",
            "Epoch 34/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.7994 - loss: 0.3350 - val_accuracy: 0.8188 - val_loss: 0.3201\n",
            "Epoch 35/100\n",
            "112/112 - 0s - 4ms/step - accuracy: 0.8044 - loss: 0.3338 - val_accuracy: 0.8166 - val_loss: 0.3114\n",
            "Epoch 36/100\n",
            "112/112 - 1s - 6ms/step - accuracy: 0.7980 - loss: 0.3455 - val_accuracy: 0.8031 - val_loss: 0.3277\n",
            "Epoch 37/100\n",
            "112/112 - 1s - 5ms/step - accuracy: 0.7997 - loss: 0.3348 - val_accuracy: 0.7808 - val_loss: 0.3284\n",
            "Epoch 38/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8064 - loss: 0.3323 - val_accuracy: 0.7875 - val_loss: 0.3227\n",
            "Epoch 39/100\n",
            "112/112 - 1s - 5ms/step - accuracy: 0.8134 - loss: 0.3278 - val_accuracy: 0.8300 - val_loss: 0.3103\n",
            "Epoch 40/100\n",
            "112/112 - 1s - 5ms/step - accuracy: 0.8089 - loss: 0.3301 - val_accuracy: 0.8367 - val_loss: 0.3204\n",
            "Epoch 41/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8125 - loss: 0.3305 - val_accuracy: 0.8031 - val_loss: 0.3256\n",
            "Epoch 42/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8089 - loss: 0.3333 - val_accuracy: 0.8121 - val_loss: 0.3159\n",
            "Epoch 43/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8100 - loss: 0.3321 - val_accuracy: 0.8277 - val_loss: 0.3188\n",
            "Epoch 44/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8030 - loss: 0.3335 - val_accuracy: 0.8098 - val_loss: 0.3281\n",
            "Epoch 45/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8008 - loss: 0.3316 - val_accuracy: 0.8277 - val_loss: 0.3114\n",
            "Epoch 46/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8086 - loss: 0.3318 - val_accuracy: 0.8076 - val_loss: 0.3376\n",
            "Epoch 47/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8025 - loss: 0.3348 - val_accuracy: 0.8098 - val_loss: 0.3190\n",
            "Epoch 48/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8106 - loss: 0.3281 - val_accuracy: 0.7830 - val_loss: 0.3424\n",
            "Epoch 49/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8005 - loss: 0.3359 - val_accuracy: 0.8188 - val_loss: 0.3177\n",
            "Epoch 50/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.7985 - loss: 0.3366 - val_accuracy: 0.8322 - val_loss: 0.3166\n",
            "Epoch 51/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8153 - loss: 0.3268 - val_accuracy: 0.8210 - val_loss: 0.3197\n",
            "Epoch 52/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8106 - loss: 0.3288 - val_accuracy: 0.8367 - val_loss: 0.3107\n",
            "Epoch 53/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8122 - loss: 0.3302 - val_accuracy: 0.8166 - val_loss: 0.3204\n",
            "Epoch 54/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8128 - loss: 0.3297 - val_accuracy: 0.8255 - val_loss: 0.3139\n",
            "Epoch 55/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8016 - loss: 0.3394 - val_accuracy: 0.7964 - val_loss: 0.3393\n",
            "Epoch 56/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8064 - loss: 0.3297 - val_accuracy: 0.8255 - val_loss: 0.3159\n",
            "Epoch 57/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8066 - loss: 0.3292 - val_accuracy: 0.8121 - val_loss: 0.3201\n",
            "Epoch 58/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8111 - loss: 0.3286 - val_accuracy: 0.8300 - val_loss: 0.3145\n",
            "Epoch 59/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8150 - loss: 0.3304 - val_accuracy: 0.8188 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8047 - loss: 0.3311 - val_accuracy: 0.8166 - val_loss: 0.3136\n",
            "Epoch 61/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8050 - loss: 0.3310 - val_accuracy: 0.8300 - val_loss: 0.3129\n",
            "Epoch 62/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8100 - loss: 0.3284 - val_accuracy: 0.8054 - val_loss: 0.3263\n",
            "Epoch 63/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8044 - loss: 0.3327 - val_accuracy: 0.8277 - val_loss: 0.3114\n",
            "Epoch 64/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8111 - loss: 0.3297 - val_accuracy: 0.8188 - val_loss: 0.3173\n",
            "Epoch 65/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8142 - loss: 0.3270 - val_accuracy: 0.8345 - val_loss: 0.3067\n",
            "Epoch 66/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8100 - loss: 0.3280 - val_accuracy: 0.8166 - val_loss: 0.3177\n",
            "Epoch 67/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8066 - loss: 0.3258 - val_accuracy: 0.8367 - val_loss: 0.3142\n",
            "Epoch 68/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8175 - loss: 0.3268 - val_accuracy: 0.8277 - val_loss: 0.3159\n",
            "Epoch 69/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8044 - loss: 0.3304 - val_accuracy: 0.8322 - val_loss: 0.3122\n",
            "Epoch 70/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8083 - loss: 0.3308 - val_accuracy: 0.8166 - val_loss: 0.3202\n",
            "Epoch 71/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8066 - loss: 0.3319 - val_accuracy: 0.8345 - val_loss: 0.3111\n",
            "Epoch 72/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8167 - loss: 0.3259 - val_accuracy: 0.8166 - val_loss: 0.3197\n",
            "Epoch 73/100\n",
            "112/112 - 0s - 4ms/step - accuracy: 0.8153 - loss: 0.3266 - val_accuracy: 0.8300 - val_loss: 0.3246\n",
            "Epoch 74/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8089 - loss: 0.3296 - val_accuracy: 0.8166 - val_loss: 0.3205\n",
            "Epoch 75/100\n",
            "112/112 - 1s - 6ms/step - accuracy: 0.8148 - loss: 0.3264 - val_accuracy: 0.8345 - val_loss: 0.3093\n",
            "Epoch 76/100\n",
            "112/112 - 1s - 5ms/step - accuracy: 0.8047 - loss: 0.3325 - val_accuracy: 0.7897 - val_loss: 0.3320\n",
            "Epoch 77/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8103 - loss: 0.3296 - val_accuracy: 0.8166 - val_loss: 0.3249\n",
            "Epoch 78/100\n",
            "112/112 - 0s - 4ms/step - accuracy: 0.8106 - loss: 0.3291 - val_accuracy: 0.8322 - val_loss: 0.3159\n",
            "Epoch 79/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8106 - loss: 0.3279 - val_accuracy: 0.8255 - val_loss: 0.3140\n",
            "Epoch 80/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8139 - loss: 0.3247 - val_accuracy: 0.8233 - val_loss: 0.3155\n",
            "Epoch 81/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8128 - loss: 0.3264 - val_accuracy: 0.8345 - val_loss: 0.3102\n",
            "Epoch 82/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8136 - loss: 0.3272 - val_accuracy: 0.8277 - val_loss: 0.3129\n",
            "Epoch 83/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8156 - loss: 0.3253 - val_accuracy: 0.8300 - val_loss: 0.3128\n",
            "Epoch 84/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8097 - loss: 0.3265 - val_accuracy: 0.8322 - val_loss: 0.3120\n",
            "Epoch 85/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8066 - loss: 0.3314 - val_accuracy: 0.7942 - val_loss: 0.3418\n",
            "Epoch 86/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8122 - loss: 0.3277 - val_accuracy: 0.8009 - val_loss: 0.3268\n",
            "Epoch 87/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8131 - loss: 0.3279 - val_accuracy: 0.8210 - val_loss: 0.3159\n",
            "Epoch 88/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8083 - loss: 0.3314 - val_accuracy: 0.8255 - val_loss: 0.3229\n",
            "Epoch 89/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8117 - loss: 0.3277 - val_accuracy: 0.8255 - val_loss: 0.3247\n",
            "Epoch 90/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8161 - loss: 0.3288 - val_accuracy: 0.8367 - val_loss: 0.3112\n",
            "Epoch 91/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8150 - loss: 0.3256 - val_accuracy: 0.8255 - val_loss: 0.3227\n",
            "Epoch 92/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8159 - loss: 0.3257 - val_accuracy: 0.8277 - val_loss: 0.3144\n",
            "Epoch 93/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8111 - loss: 0.3279 - val_accuracy: 0.8412 - val_loss: 0.3050\n",
            "Epoch 94/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8072 - loss: 0.3284 - val_accuracy: 0.8143 - val_loss: 0.3179\n",
            "Epoch 95/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8106 - loss: 0.3263 - val_accuracy: 0.8188 - val_loss: 0.3153\n",
            "Epoch 96/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8106 - loss: 0.3251 - val_accuracy: 0.8188 - val_loss: 0.3114\n",
            "Epoch 97/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8139 - loss: 0.3289 - val_accuracy: 0.8166 - val_loss: 0.3273\n",
            "Epoch 98/100\n",
            "112/112 - 0s - 2ms/step - accuracy: 0.8120 - loss: 0.3232 - val_accuracy: 0.8322 - val_loss: 0.3109\n",
            "Epoch 99/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8080 - loss: 0.3281 - val_accuracy: 0.8300 - val_loss: 0.3128\n",
            "Epoch 100/100\n",
            "112/112 - 0s - 3ms/step - accuracy: 0.8175 - loss: 0.3242 - val_accuracy: 0.8233 - val_loss: 0.3095\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78597ebe4d90>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Set the input and output sizes\n",
        "input_size = 10\n",
        "output_size = 2\n",
        "hidden_layer_size = 64\n",
        "\n",
        "# define how the model will look like\n",
        "model = tf.keras.Sequential([\n",
        "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
        "    # the final layer is no different, we just make sure to activate it with softmax\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
        "])\n",
        "\n",
        "\n",
        "### Choose the optimizer and the loss function\n",
        "# we define the optimizer we'd like to use,\n",
        "# the loss function,\n",
        "# and the metrics we are interested in obtaining at each iteration\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "### Training\n",
        "\n",
        "# set the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# set a maximum number of training epochs\n",
        "max_epochs = 100\n",
        "\n",
        "# fit the model\n",
        "# note that this time the train, validation and test data are not iterable\n",
        "model.fit(train_inputs,\n",
        "          train_targets,\n",
        "          batch_size=batch_size,\n",
        "          epochs=max_epochs,\n",
        "          validation_data=(validation_inputs, validation_targets),\n",
        "          verbose = 2 # making sure we get enough information about the training process\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the model**"
      ],
      "metadata": {
        "id": "wSwVhPnEUn6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
        "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ],
      "metadata": {
        "id": "fCggsiUkVDu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a43b1b-b41f-4b95-a098-cc6ee20f2d76"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8005 - loss: 0.3350 \n",
            "\n",
            "Test loss: 0.33. Test accuracy: 81.47%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}